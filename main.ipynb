{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf8e6dc",
   "metadata": {},
   "source": [
    "## Neural Radiance Fields (NeRF)\n",
    "\n",
    "### What a NeRF is?\n",
    "\n",
    "NeRF was first introduced in a 2020 in a paper [NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://arxiv.org/abs/2003.08934). A Neural Radiance Field models a 3D scene as a continuous function:\n",
    "\n",
    "$$\n",
    "    (\\mathbf{x} \\in \\mathbb{R}^3, \\mathbf{d} \\in \\mathbb{S}^2) \\rightarrow (\\sigma, \\mathbf{c}),\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}$ is a point in 3D space, and $\\mathbf{d}$ is a viewing direction (point on a three dimensional unit sphere). The underlying MLP predicts two quantities: $\\sigma$, the volume density, and $\\mathbf{c}$, the color.\n",
    "Images are rendered by marching rays from camera pixels through the scene, sampling many points, and alpha-compositing the colors using the predicted densities - differentiable volume rendering.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"figures/pipeline.jpg\" />\n",
    "</p>\n",
    "\n",
    "### Rendering\n",
    "\n",
    "endering an image amounts to accumulating radiance along each camera ray. Each ray from the camera can be represented by an origin $\\mathbf{p} \\in \\mathbb{R}^3$ and a unit direction $\\mathbf{d} \\in \\mathbb{S}^2$. For the $(i, j)$-th raythe points along the ray are parameterized by:\n",
    "\n",
    "$$\n",
    "    \\mathbf{r}_{ij}(t) = \\mathbf{p} + \\mathbf{d}t, \\; \\text{where } t \\in (0, \\infty).\n",
    "$$\n",
    "\n",
    "The color of $(i, j)$ pixel is given by\n",
    "\n",
    "$$\n",
    "    C_{ij} = \\int T(t) \n",
    "        \\underbrace{\\sigma(\\mathbf{r}_{ij}(t))}_{\\text{volume density at current point | }}\n",
    "        \\underbrace{\\mathbf{c}(\\mathbf{r}_{ij}(t), \\mathbf{d})}_{\\text{color emitted along} \\mathbf{d}} \\text{d}t.\n",
    "$$\n",
    "\n",
    "The function $T(t)$ is the accumulated transmittance (survival probability) along a ray from its origin up to depth $t$. Using Beer-Lambert law we arrive at equation:\n",
    "\n",
    "$$\n",
    "    T(t) = \\exp \\Big( −\\int_0^t \\sigma(\\mathbf{r}_{ij}(s)) \\text{d}s \\Big).\n",
    "$$\n",
    "\n",
    "When it comes to rendering physical scene, the $\\mathbf{C}_{ij}$ integral is often evaluate on the interval $[t_n, t_f]$ which corresponds to the values between near and far plane. \n",
    "\n",
    "### Improvements\n",
    "\n",
    "Here are known improvements to this basic NeRF model:\n",
    "\n",
    "- Because there is a lot of empty spots when sampling the densities, authors suggest simultaneously optimize two networks: one \"coarse\" and one \"fine\". First we sample the \"coarse\" network $N_C$ using sampling described above, using the $\\sigma$ values at each point, we are able to compute more informed points $N_f$ and sample the \"fine\" network on the union of two sets $N_C+N_F$.\n",
    "\n",
    "- Improved method: [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields](https://arxiv.org/abs/2304.06706) - uses cone tracing with grid encodings, greatly reduces noise and depth aliasing.\n",
    "\n",
    "- New method: [Gaussian Splatting](https://arxiv.org/abs/2308.04079) - represents the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space.\n",
    "\n",
    "\n",
    "### Tutorial\n",
    "\n",
    "The dataset is in the `/data` directory. It consists of procedurally generated photos of a LEGO truck. For each sample in a training batch, we need:\n",
    "\n",
    "- **Image**  \n",
    "$$\n",
    "    \\mathbf{I}_i \\in [0,1]^{H \\times W \\times 3}\n",
    "$$\n",
    "\n",
    "- **Pose matrix** — camera-to-world transformation for each image.  \n",
    "  The top-left $3 \\times 3$ block is rotation; the first three entries of the last column are the camera origin in world coordinates.  \n",
    "$$\n",
    "    \\mathbf{T}_i \\in \\mathbb{R}^{4 \\times 4}\n",
    "$$\n",
    "\n",
    "- **Focal length** of the camera as a scalar $f \\in \\mathbb{R}$.\n",
    "\n",
    "First, we load the training data. Activate the virtual environment and install the required packages with `uv sync`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e20c569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Shape of train images:  torch.Size([100, 80, 80, 3])\n",
      "Shape of poses:  torch.Size([100, 4, 4])\n",
      "Focal:  111.11110311937682\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMblJREFUeJzt3XecnGW5//FnZmdm+256NpsEUkkBEroUJQGkCQJGOtgQBEXUn4p4xMJROOfYOCJgoaMioQjSpLdQQgshgRBIIX2TzWazvc1O+b0m/s79e1339/bsLkePJPm8/8p9v+6dfeaZZ3LNPtdc1x3L5/P5CACAKIrinAUAwH8hKAAAHIICAMAhKAAAHIICAMAhKAAAHIICAMAhKAAAnETUT7FYrL9LAQAfQP2pVeYvBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAADgEBQCAQ1AAABAUAACKvxQAAA5BAQDgEBQAAA5BAQDgEBQAAA5BAQDgEBQAAA5BAQDgJP7/PwHAuv7yKXJKPjpzpMyN//g8Tt0Ogr8UAAAOQQEA4BAUAAAOOQUAf9OGDa0yN+6SGTKXf32WGcf2eZazup3iLwUAgENQAAA4BAUAgENQAAA4sXw+n4/6IRaL9WcZgO3YrVfuZcbtHd2yJhnPydz4zRvM+MirOv4BR4f/qf78d89fCgAAh6AAACAoAAAUxWsAnLola8zZqB43Qs7OxvWdMnfe1cea8fyiB2XNQVdqfgIfPNw+AgA4BAUAgENQAAA4BAUAgEPxGrBDssWmv7j+z7Iiv/5bMpdJ95rx4BItWu2MpWSuwv/KyrJNsmbXQbbo7YhftASOG/9IFK8BAAaE20cAAIegAABwCAoAAIeKZmAHNHn6JDPOR8WyJpWaLnPNG18w467utKypGFcjc2sabbXyZTccIWse/vJj9pgaZsua2PBnZA7/u/hLAQDgEBQAAA5BAQDgULwG7IAuuvRmM37ztXmyZuKuQ2VuTPE9Zjx4iKYdBxfrzmtt+UoznjJGC9yqliwy42ygCO7pylEyd+l335U5vD8UrwEABoTbRwAAh6AAAHAICgAAh0QzsJ379uU2qVywaIlNzpbnWmXN7ONOlblda4eY8St/Ok7WtLTqdpy148aacbZHO6B+5ycHmPHLlz0ua1I9Wiy3z4/bZQ7vD4lmAMCAcPsIAOAQFAAADkEBAOCQaAa2M1OmzjDjnh7bobSgdes6M/7Yyd+UNc8/Y6uXC8aMGWfGlYNs4rng43vNl7lY3H6+zKaSsubCC21X1pv+z9P6OEn9uaOPslXOo+e8LmvWPXuszI2ZZB8rNvr+aGeXz+f7XMNfCgAAh6AAAHAICgAAh5wC8HfWtuQEmfv9jRmZ+9KVf+nzscaMD+yOVr/KjNs7u2RNdWWJGZeUam7guDO/JXObGhrN+JzT9Lk8dcfHA7/PjlMx7a46oqbcjL/0vT1lzU0nap6jPVtkxnOOGy1rxpyyh8w99rvlZvzyai2M+/419lzu6MgpAAAGhNtHAACHoAAAcAgKAABHs0EABqRj0Ylm3NisBUJrO1b0+TipZLHMxdvXylwosexrabMFbaUl2tm0u71B5la/9YwZ/7pxmawpq/ikzE2Y8IQZp5J6DrKRTRhHOf1MOmpcjcwde8YUOzFUz1NsxIMyl99gj/OolG4jurMlmvuDvxQAAA5BAQDgEBQAAA7Fa8D/0CVfGW/GjbELZE2qYoTMba1fb8axLa/Imtv//MDf5fUZMUTvwx919Okyt6Gz2owv+64WuF37FS2oq5lUasaDy/XzZm/a3tOfPsX+roKzPmPPZcHaq2yeIz3Eq5QrFOdlND065qx9zXjDoq2y5rf32MaBP7rZviY7GorXAAADwu0jAIBDUAAAOAQFAIBDohn4O5tz1sUy19SwRubKi20x14MP3P4Pey2u/t4+Mje/8TSZq99YZ8YlGZuILZhS/oLMVQ2yz6W6pkLWdHj1c53N7bLmil8fInOvX2IL4yYes7esqR6tiebYtMeivuTbTrY/U3l3tCMj0QwAGBBuHwEAHIICAMAhKAAAHBLNwADEK/Vz1HEfPc+MZ5TeJWuWNH1Y5kak5pvxdfdp19L+KEtotfJv/n2GGd+77FRZ89IjN8vcqMFZM35nhU08F3z4iDkyN7XcVl7ndPfRaN+97JagTdlAk+as/mCmy57zz+6qCer2Nu0cO37mSDPe9E6TrKk5zSbgV8y325EWTD5ZK823VySaAQADwu0jAIBDUAAAOOQU/s7ynZ/XyZ5eO44Fds6KeZU9PdpBMiqzu2lt05G042RWH3qIFuRkFh1lxomZfRf67Iwmjh9nxg2bt8ia1g69x+27+IxhMlfVU2XG+dIOWfP92+r7fOwbfrCnzF3wb++acarI2/UsiqJzjiqRuTtftt1OTz1Ku7vG0ppnKKtOmXGiWD9vtm+xz2/4KC1w27DZe68EfPFEPab0Sn0Nxs8YbsbDjrc5nIJR3kZvdfrUdijkFAAAA8LtIwCAQ1AAADgEBQCAQ6L5b8jXnaOTpWkz7F2wXJbc8KwWv3zxPJuszLdpgc6q3e2WgxO2nqG/P5cOzHkFQHFNNEd2F8S/SnnrWrUAKqroMcPYkHujHdmjjzwrc5868zgz3ry176RyyHfOtEnPglgsb8ZFkb52HcNtwVfBlPIyM77w56tkzYxpu5nx4RNWy5rFm2bK3OCqZWa8y3j9/ZuWrZS5EbvaL0aUl8RkTfUQe9x1m/V67ujQ90bMeyh95Ci65idTZW7t7QvNeNeva/Haziaft9dcCH8pAAAcggIAwCEoAAAcggIAwAm0Kdz55Os/o5PlWj28+BabiJxx8sGypvZ53b4wKrJVx7fepAnqz3rhuXWEbs1YtfbkwGN7ycl8IM7HAi9zxqugLgn8XD6Q2N5OXfz9m8z4m8fcIWsOOeUEmXu/iWVf0SCv8jyKou719rHLhtpq4oLO5P+RuW9cc5kZX/3lI2VN3Vp7rf7wzq2y5qofaHV2b9pWC19/u17Phx5oK7ELct7ny44u/XZDqsfOdQaSyvFAFtmfC6VKv/Ev78jc2bvbLqn55ybJmreeXmHGow/YXdY8+ZC+X0+5uu9K8+0VfykAAByCAgDAISgAABxyCgUp7SAZ5WzXx4IZpx9jJ5J6z33YmLH6WGW2Q+aQtOYr1nvjEaEbpz22mKxg3Zv2J8fuZ4uWtokHcgP+bl2hiqCYnoPtwdZXj5a5RGyuGa/ZqOfy3GO0a+e3b2z5uxzTj36l7Tc7ltgCxeLiwbKmeualekwn2vzEhrp5+vu8HMINl+0ta7piet0vXmCL1xrbtKhx6fzNMveho0ab8agazY+sWhPoDuwpiuuFH/cuzlygGDNXpJ9vn17basYjizWH8vIWe43n/2JzDAVdWX1znHv8AWZ8w4M7zu5s/KUAAHAICgAAh6AAAHAICgAAhy6pheRSy3mRyGqxUeQnwQKJ5qhDk1JL7rcJr87KQH7/wSfNcOtuGq+P/vJhMvfEVbZI6aOf3UvW3HjnezL3+TO9Qp7eQGa7xNuuMaXbRcaGPhx90Fx93lCZa/LyyqUZLZyqT+o2jz+7VQuX3o+2hZ+UuWTcJjm/9YsXZE1VVpOz+V6bab3idu3M2x/nHqdbvhZ5nUx72nV7zM4WPXcTptnHqqzQJPb69fYLFuHvUmin2MNm2i8AvPS2XochZd73JCYO0ffmBVceaCe2ekWdBfV6TI/evMiMj/lpQ7Q9oEsqAGBAuH0EAHAICgCAnbt4rXvxuXZii+5KFQ2drHMx715q2t5/3aZI78HufkJl32f9Q97vS+n93ihQS5ao8o6hWCt7iltsTmObtC3KuvpWvSd60ae9e/PLmqPtwUXX6z32750xyIwXbNLcy+nHhxoADjyn8ONLZsjctX9YIHNr6u210turL/CwYTUy9/1r3xzwMV19ue5M1rhV77HH0vZO//XP6vV82HQ9v1295WbcvF6vlXyu712/kgk9pvnv2rxKPNA1z9vE7v8dk518K9DD7vHrbbHekQdrXikaZJ9bQWu1fX9e+UV9U3/91xuj7RF/KQAAHIICAMAhKAAAHIICAGDnTjRv8JolvnHvYlkz5yJNzL3w4HNmfMiJh+iD9wQKiUq8ZGFWi3+iQXvYcTywJqcFQbPPOdZOtOoOVGVpTaAuetl20Rzc0iRrfnN1mxn3NNlxQX7pbJmLTXsm+qAp9a7048ZoYr22Zvj7euzLPlVrxukm7cbZ1KhFaLli+yWBJS1HyZp44qH3dUy3XDHTjF9f7PfhjaK7n9YvJRzs5d+P8C7Lgp5eTfRedd3bZnzhWZogz8TsZ9BYoDPvxyd6BZNRFP3lPVt5mA/8XLJIM8157zNvJpCMvm+eTYgfeZxeA7HRD0bvR7JID7Q323ey/Z+NvxQAAA5BAQDgEBQAAA5BAQCwcyear7rpETPOBCotj1+rFaiH7GOrGC/90n2yZsJYTS59/tunmfE9t9uOqAVzPu1t9blxiay5d55uIfn4s3b7wHigtPOar+wic12JIXaiXZPRCxfbpPmmZk1MrlqiSdX+mHXEMVq5+rzt+Jru6Xv7xv76zu9tQvEHp+tz2adspMw9+kPbTXb+u7o958omey6HdG6SNZWBHV+b8/Yz2YiR+vtXddhrp+C8024z4/IO7Rra1G2vw+Yu/fzXG9OK/PrM/mb83GP3RO9HNqNPuMgr2A4VOD+wQq/xKG8X5gLJ2i+ebZP9Bb+aayuKY4HMtp+0/tIlWsH+/Pe1yvmQC+x2nCvvXyprJu6vW/PG9v3gfQnDx18KAACHoAAAcAgKAACHndcKRUOPHRf5ph8wReZef952VPzFFU/ImsG7anfTDU32/nVrW7usufz8fc24bvFbsmbmMafL3JjEQjPurd5N1lz8n0/1/Wkgoemlb59sO4s++Hubv/hbdXjTZ9l7sLNPs8+tYI/97pe5dU3FZnzR2VpAeOtDNjfQ26tdPPO9movIZuzcF4/QnMInPmPvpxfcc9NLZrypZ7SsKRp9ghm3BLrS3nHXDVFfTj7nhzK3pW6VzI0bbE/6hEGvy5q6zZvNuCStL1R3UruyLmyz74WXH78p+ns53yvyi+eC/yX1uVtYoElqcBe3fjx0FPMmY4G8Q0Y3XoviXrFcMnBQ7YH0yE1ztYjwfxM7rwEABoTbRwAAh6AAAHAICgAAh0RzFEWfPcHbdrKQmKvQbo0xvzCsQbuGVlZr0c76Hlsk9Mf766K+fO+TXnFZFEV7Tv20zM19zRa5jdwt0Ll1q27f2Nn5ghlvjJ0qa3591tNmfN/9um3p9/6oSfN//7RNth8wUpPBn7/L26I0iqJ3V9nOrddeoB0rR8+YYMbpTk0xdnRoIV53p+2KurVVjykVSLYnszZB/cpCfb5rumxyP1EyTNZMPvBomatvtsfQXKeJ/LYOTZrvMcR+waG6u1vW9HgJ06LqCllz7e0bog+as0/QQrHVa+z77PlF/StqPPfkUWZ84590e0wvh73DI9EMABgQbh8BAByCAgDAISgAAHbuLqm+6vHanXLxck3YDit+zIx3K9GkclmZxtkf/9vuZrys03beLDhwmt0HsbJmoqy55eE7ZW7vI22V82P3/FHWTNjDdnQsKPKS5gceeLCsSU78mhmXj9CtN4cM1oR8T7m9rOoDlZ0lxZoMHuHl1oeM1S6TdctsB9JYuXb6TMb1sYcMttW7bZ1a4VtcolWp++493Yw7SrQDasV6OzelRiuav3HVd2Vu1hFzzHj/Mt32sSVlq7wLyvL22HurS2XNXiNmmfE7a3Wb2K+dpBXjvj1GaYV+dVz/22jstec8lgxsj5m15zceqALOBaqc0002IX7NubrV5xvvrZO5G+621f7oH/5SAAA4BAUAgENQAAA4FK/9DeedqIVTla325nhbjRZg7RrXwppkly0uuvQ+vef9zW9ebMYN3n3qgknl2u00NdR29qxbYXcvKzhgtN7f/e3aT5lxd3OgsCdn7/nuN1p3jfrUrHKZ+8ZvbYfOeb/XXMRV1+tOVVf8zj7nX37H3s8vWLV4pRnXTNC8w7qNuhvc5HH2vvvMvfTnlm3Q16Wzy97kblitBYtLV9rzdPMj78ma316yq8y9utB2zJxUPEiPqUgTMvOX2mK52XvobmHl7fb3zXt7raw5dPfxMrfLSHvd//o+fc1TSc0pzN5vphl39WpyIO59BK3buEbWdPToa5AoqTLjCy8+T9ZMnK7nd7fd5wy4cGtHR/EaAGBAuH0EAHAICgAAh6AAAHAoXvsbiiq1aKit3BZAFQVC6oub95O5r0x7zownTrFJuYLOrk4znhDX7SonTRwncy1vP27G//qw7h249ISvytz6914x47FjNOkY5WyCPJPW5OH+R2vhX8WtSTN+9Fn9uepK/blhFTYZmsjpCR4z3utoW6yFW/F2TQb39tife22lfiFg3ou6VWJHj0309lTruXzkkcvN+Cdf0XO5taVF5vaeeqAZz1/6mqxJldlzWXDQNJtY7s1rEdjCNltU+JHDD5c1y163nXILVtXZLxzst7tuS5sMFNSt2GC/JHDZz78ta4YPt4n0fOAzaU9nR+D32fddokj/28rH9BrbuOIvZlwz8VhZA8VfCgAAh6AAAHAICgAAh+K1v+HCz06TueJOW5TVmdJmcCcdpAVtbZvsvfnm1N6yZlDSFugsXvayrPnl3Xb3sILurM0hfOE4vcf+i4u1IV682Lt3m9Qiqa9cYXcCm1ykTeSW9er93c8dYwug6tt3kTWdXXrf/7AD7DHVb7H3kgsqq2yDtnkL9F59JqfHmfIKl+5/VfMHXRVfkLler4Dv6Xt+LmvOn20/W02coYVxC5fpa5f0PpLFc1pc1d6oO71VjrL35lMxzSNdf5/9ud9+fV9Zs9ex58pc5KUnMr16XQwdpg3pbr7hBjNu69HXrjhlHzyX1ddpaLW+p+bMOdGMkyXaBDFRpM0p/Wq5kZOPiXZ2+X4U8PGXAgDAISgAAByCAgDAISgAAHbuRPM9P/mWGfek9RTctlATmJ+oeMSMX+rWBN/EjBbfDJ1gk8htad3N6vs315lxLpB0fPAXH5G5w/ayPxeNPkjWRA3aRTMqsQm9bJMtnitY9Ha9Gf9xnk20F0yOD5O5879qE4Fb6ntlzbBRo2Tu3gfetr//XU1Gt3l5z96MnqfAqYsyvfa16u3UY9o8+PMyt3WLTRAfMNheA9vEbFI1Hel10RGoE01vttfYxtX2CwkFk2faa6fg2bU2aXzinm/JmmUNdre/a3/2ZT3uwM5nicgWgeWKtFAtymuh2IOP213OdtUmw9FLryw24zPPPlUfOquvS6v3oo+u1UR3IqGfb7PeFw6qAoWOZeM+Gu1M8iSaAQADwe0jAIBDUAAAOAQFAMDO3SX1ylvnmnFZIDR+vUETr7fNtsnZDR2HyZralE2mFVx4zSozThZpAvXqS2xiMBnTyuj27BiZu+W2+WY8cjetxD5kipeMLlRVR4ea8TuLHpM1y+ps4jOX0QrUN2ONMvezZ79jxqcP/oGs+d192qFzc4d9IQKFulFP2iZH44Fk/yknaCLysYdsBfMb+vJGQ6tsN9uCrpJ9zDhTrBW3Xa32wcrKdU3Vej1PWyNbhTt5H68DbBRFm9a1ytzRUxaZ8a/u1DUP3/0JM04GttDMpnXryyilXVnlsR95XuZOPv5gM25u1cd+bWmTPaa8rrn5jodk7pxP24R0d48m5It69dsFKS+x3BmooIbiLwUAgENQAAA4BAUAwM5dvHbeuWea8X/84Iuy5htjtVBs7QkXmXH50NGyZt27L8nc7Mn2nu9HJq2RNeMm2iKat1fanawKXntH8xX1zbYQ7vQLbbfKgvt+c7TMNbXb+6vlpfr5oMR7zRu26G5lQ0Zpx8oTLnjGjHtf0B2vTj1lT5nb0mLvuze1a6fNl96whUwPP6WFeenqOTI3Y5rdte69V34qa6qH6HPp6fGKuRL6PhiUtffGK2J677qjV8/vxi3255Klet8/OShQcFViHytZ+zVZc9FZk8w4G8gHJQLFXKmkzXMENjSLsoHJeMz+3E03/VHWnHfOaWb8wCOBnd82afHnF862u8Y9/qTdNbDgyI8eogfqH6PfAraQi/DmRkw7PtqRUbwGABgQbh8BAByCAgDAISgAAHbu4rXRg21u/eQv22K2gthJ2lWyu80mQuvWviNrPjzmVZm75FhbdPbQE9ptdL/97DG98qYm4Q484ASZe+TJv9jxXX+QNc1NWuyT87YqbGrR5GHO6yx6/eXTZc3Pb94gc5d913ahffUGm/Qs6A19vyFmC6c2bdWOmSvqbaFYecVesqY70MXzqadfNOMDJ2iS9Y0lWgS2y2RbUPa7P2v33M/NsdtjVse0s2lpXM9TZa0tUEx4Sd6CVJEmR99utl8ciLcslTWdrfaYGpu1UGzcrrpNaixjX/Nc4HWKJwKFcFm77owzbPFcQY+3temWOj0nF55zuszdeef9ZrypUzu3HpXT13zT5i1mPLJWO/MmAud3Z8dfCgAAh6AAAHAICgAAh6AAANh5KppDx335t2xlZc0UrYac97QmjGdEj5vx2+2aCE0FtjicNq7CjBtWacfMDi8+b+nQ7p+NPVpxO23/C824NGeTawXfPNVuc1lQFLcJ2+ef2ihrrn3hw2Y8Y+STsqa5K7DNZGSTs+VltjtmQWeXVthuXWmPvaS2qs8K1JVrJsiaTOD7ExN2m2rGbetukzW5mP5cS9dMu2bweFkzZJB9vhMSf5I1ZR2axN7Uad968Qqt4B5WrR1XFzXY6vfKUr3mZtbaa2zWUUfJmvG1ui1sZ9ombKurdU3Cq14u6MnY90IyoWuyXi64sbFZ1owcqft43vYHWx19yqmaxL7r7gf196VGmPGcj+0va3rT9rgn72f/b9ie/+8LoaIZADAg3D4CADgEBQDAzlO8Nu+Ze2Xu3TftzlVvrCiXNas3a6qlutbeWywbpvd7U8V6L7WxzRYOtbRrIdGgqXa3sMqUPs60QFFWcebXZjx67BBZs36dxv6JE22eY9aRWthzxf12x7gtRVoEt67obJn7xCfsPd/udCA/slWLwP78lN2xrXeF/r50j+3U2tvzlqzJZfT8vrpQO2v6YoF80DGnHWHGPd496G3HlLWdPTvTuq1bW06vld6M/bnRlVqU1dKouZeM91kurpdKVFJku8lOm1Ara+6ae4fMVY+x3WsP3V+Puz2wg1l5mb2ekqECt257TCNG6LUaRfq+m7rH3mZcVqznqSqhr/lJJx9kf3+ku8olvF3ytqyyecOdEX8pAAAcggIAwCEoAAAcggIAYOcpXnvlRS0kam+1Ca8bHtCupVXFdk1BbtMvzfiF5dqh86BJr+tB9NoE8Ttva/HannuPtL8rcL4HdetL1ZKy6353rxaKfeoTtmNmQbHX1bInqZ8PRiTtOVi7Uc/JG02H9pkInVL+sqyJ5TQxmOmwieV84CNLImmfbz4WuHxTWgSW6rW/Lx9YEw91BPW6aNb1HChrcsU2SV/RpNfc+DGa5Fy9ss2M993PXgMFc1/VYrkJE20h3qAyTep+ZE+bjD3p6P1kzfx5dtvUglnH+NtRBorQAon8uHc+n3/WdqUtOHy2PXddvXqN3/Ggbmc7apB9/yxYbL8AUfCNC+0WuwVrN9liyDG1en79SyztdYktqAp8dq7e/ePR9ojiNQDAgHD7CADgEBQAADtPTmHxK9ooq6XVFg1dfZfuAHXAdNvkrOCdly8141jo1OX1nmQ2Z9d1duoOZqsa7Zq9JqyI+kMOIda/1y7nHVOgbisqjtt7ua1NXfrYgYK6jFe4VLeuXdaUleq9ar8kKV6m9+G7M/a4U3G9n16W1Nel26s56+jW++LFCf2M1JG2j/XGUs2rjBpi13S16ck87jAtHosX22vlC+f/UNZsqdd81+iJdse0X/3ndbLmkksvMuPrrrtd1px2+idlLh/zXs8iPb8VJaV91pzlArmeuNdI77kXF8iaWR/eR+Zy3o5tcx+YL2uqS7Sgbv6b9n196VdOkTXPv7LEjA86wBbvFaxZX6fHefT50faInAIAYEC4fQQAcAgKAACHoAAA2Hm6pG7cslXm6uvqzTif0yTV8y9rEVplt12XSGhCMR9IvPpJuKWBnddSg8aacS6YxM6/r0RzoPGkrPNq2bbp6LWTw2p057dOL/G77bG8tp1jizRh3Nigyeds3hbZJYs0aZ/yioty/nZehS8XrNFdzlbU2c8/iZw+9vQpY2Ru0TK7I11JsXYN3X/P3cz494/qTnfPLtRrrNNLoH5yju6aN3m3XWWu13uxDp49W9bksvb5NjTbL1cUlHkdQgt+5SWkjzz6SFlTMyzb5zEVp7STaSJhf+7AAzWp3KOnKbryqhvMuFm/7xD9y1e1eC0qss+vN6vHfehBtgC1rVX/v5g8wSb2d3T8pQAAcAgKAACHoAAAcAgKAICdp6L5lluulblMxmazWts1AfXQE7rNY03RQ2YcC4TUfBRINHunbv7zmlCMldoOjrMODuyxGHps/9XzKpVDv7+g2+u42hWo8E1I51R9oFggi93YbM/v2o362KvX6LaWlaX2sT60h26TOn+h3epSH6VQlavn7oBJ9rksX60vXmdCO6e2tXX9t11Tt/G+qDBsvHZS3Xd4s8wtWGmT2N+5SCtu165ZL3M93vWbTOpxF3nXypqt+hqMHTVc5r7wOdv98wc/vEbW/PzfvilzUTze53WY99bkMno9P/28bpu6pd6+X046/jBZ897aTTK32+Rx9hAD/4f53QZSKf1SRCawBWt1sV1XOflj0faAimYAwIBw+wgA4BAUAAA7T/Fai9bsRK++Y+8jtrTponhS72e/03CQGU+o0t2lsoFbzg8/ZQtikkVa2FOas8cw7yW7C1nBhk16Dzbt3SpOFAWKyTKBIjsvIVLkd8cs3HMeZsfrteYuygW2R4t7HTKn2I3JtgllqD4yxc4uWK7n4KBJ9l7uE+9qtVMmq3MLVtqfiyU073DuZz4rc9f99jdm3N2rjx33Xs+OutdkzUMr9J7+lMkzzPiG3z0sa+66yXbmLfjtjXPN+IJzz5I1c+feZ8aXfvpkWVOS0teuxMtFTJ22h6yp29Agcw2N9uLYc89psubF5+yuah86aH9Zc+iBe0d9Jc421uvugi+8pl2FJ06wBaE/v+kRWXPJBSeYcXubFj4Wl1bIXI+fQ9mB7LjPDAAwYAQFAIBDUAAAOAQFAMDOk2he+d5ymTt0d1vU0pPWxO/c+zWZVZy1RTSjp2ix0TVX28RkKFFWFKhLa2iySdWJ+35a1qxcfXPgsW1yNh1M/EZ9dnPNBj4fvFdvk6rxwNaMoWIYv27pzXWaxI4HEnX3L7DrUoHtMR9vsgnbeCLQjTPSZPDwUbYD6n77aofOG2+9TeZqJu5rxr0ZLWRq2vienchpUnn67rYbZ8GgmL2e3lmnHToDjT2j8aNr+ywCqx1jk6zVgY6ot91hizELJk6ZasZzjj9A1jRsaZO5PfaYbMY9PfolgYMPtonlWOAaKPI67P51of2SQO0ovQ6/9Bnt5prxOsXWjNAtdh9++HEzXrRKn9vF558kc++utFt01r3znKypnfqRaHvEXwoAAIegAABwCAoAAIegAADYebqkfvzEY2TuuI8da8YPP/W8rFm1QjuZVld6Ww5qjjN65RXtrjpil5lm3LBaO0HmvFLofCChWZTSJFyvV9LcG9iesqREOz92ddrHLy7R5F2vtx1nLqePHbp8El4mPXyJ6VyRf40FOpLmvcTrYQeXypq31ui2moniSjPOZTQZPKJGt77Medt2hrZurayypd/ptG41unatl4yOomhwmbddZI92RL37xu/LXIlXjZ2LB17fdlshXz3EbnVa0NOl19jgwXbL1S0tmjB++kXdbnRQynavXVan5/e8M21305Z23Vezoly3fC1O2S6w+cB1WJTQc7Bq1VoznuxVOBek8/YaW7Xadq4tqB3plfZHUXTT3EfN+LzTZ8masTNPiz5o6JIKABgQbh8BAByCAgBg58kpXHPtf8rc48++YMazD9YCnU0N2gly2ZsLzXjPfT8ka378H7rTm9+Qc1iN3vNOe/d3x+66m6xZvVxzH34B0KBh+nON9UtlbswQO17XoFVSQyvtvdsRw/Re7vAyvS7mvWkfq6Mr0Lk18HmktMTmBw4/UHMoJSl7DJmc/v66tO6C1d1iX89UxWBZE9pUrTeyx9Da3t7ncVcHuo/2dGsn3qbWFjNevkQLoL56jhZOfeGc48w4m9Xzm/EK2iqrbU5lm8BbP5W0ibJcNrRDnt6/78zY5/zsi5pb22W0PecPPGXfTwUXfeZombvypsfM+OvnHi9ruro191FWZvMTyUAxZNZ7fkWB/EwgTRcl4/YaTwfaI4+ebnexK+jnf7f/MOQUAAADwu0jAIBDUAAAOAQFAMDO0yV1/oJFMnfkrIPNOO3vaVlIEo2qkblhlbbrYW8gplZW6TaeyXK7H2VNrRbRRDGb4CsKhOvSwbYTZUG+0xY8tacDCa9d99NjKqky46njq2VN2wabkB89qrFfX0A4cpbXubVXC5Le26BdO8tLbcL27ZXaqTbhFY8tX7dJ1gwdPk/m/Eaio8babqAFFVVDAr+vx4zj3naVBWmvI2iiQpO6zZqfjla9O9+MJ+4yWtZsbmyWuYb6zWZ8y5/0+X77IrtF57IV62TNhHH6hYe893yLkprs79L6PUn0Hn7IdH1s7/3y1c+O1DUJW6hWMKLKXiuvvqYJ6mde1e04v3m+3YL0nid1m9RjD/W2/8zbIryCWKgTr9cxOJvRn9uw9AGZq52qSfIPGv5SAAA4BAUAgENQAADsuDmFK/7jX8140WsvyZq417Bt3vxXZc3hh9q8Q0HWKxSLB4qGmrbUy9zkGnv/uqlNG4ENqkr22diufIjeAy4dMsKMU+Xa+KyjTXf0intJi5ZNq2TNkiX2Pu36jZp3iAUa22XTtiCorUNzEaFd1dLejf9Qmc/gQbYAKhs4T5s3b9Af9IqGxk09SJbkvOZof/0xe62UFmtxUyJl73k/++S9sqa8RI9z5gSba2ro1nNyyVdPlTl/t7l8Vt/GGa+R3yNP2vxFwde/dIbM/eGPfzbjs07/hKxpbmmVudJym0cJvDWifGSPKVGk5zJ03X/qFNtsLl6keYeOtD6Wv4nbulWrZU16//FmfOuddie2ggvO1cZ2i5bYHR13m2wfp6Cny+Znthf8pQAAcAgKAACHoAAAcAgKAIAdN9E8ZIgtQDrso7rzWiZrq2/SzZqYfPX1BTJXM2y4GS9ZvlLW5CNNVvrdGUsrKgJr7EvR4nXQ3CYW6BpabRPLXV3aLbKkzBaqFbz23B1mXBRI3sW8TF1zi3b6zHsJzYK4V9CWC5yTnkAmMuclg4v8TOG2Y/DOS1wv4SKvsKgg6+1k9/rzf+pXB0k58ph+jqoZaa+Lr33uKFnzs+tsArfglFPtukMP2UPWxJOJPo/p6xfO6fMcnHCkJtYzvfrajR1jk9/FCS3sfPo13Xlt1odtgeRtc++XNUd/3D7f0mS8zy6tBXHv/dPdq51bjwicOz9l/aXPnRB4bHvd14yeIGtCX3iYN88m7ieNHSprfnWLnoOGt+zc8D30mP7Z+EsBAOAQFAAADkEBAOAQFAAAO+52nL/6zS/77Dbak7aJ5o5mrbgtqdTK4J52W8mZDSQ5f/rz62Sudavt5JlMadfQaft81IwTgYRbPrA1YrdXPbx8yYuyJtOl3Ub9lzMfSGJH+VzfidhA4tVPzYWusHjg3OXzNvE5ZMQwWdPaaF+r0RMmyZq1K2y1acHQETYZ3Lh5ix5TQju35jK2KnXoSO3s2bjZVrHPPmjvwPaj+v4574zZZnzHo4tlzZWXatXxj679ixl/+4u6/WjO/zKF3yY2iqKqcr0OMxn7c8m4HveqQGXw4Cr7fvndr+0XGbYdg/e+C147gevQn8oHtmCNB85vNmefc9zrSFDw1R98wYzLvK1V/3qcepj+NqXxwPv10WfekLmjj9jHjGun/O92TWU7TgDAgHD7CADgEBQAADtu8Zp//3r+a3qfdu8ZdleoUu9+aEHC66RakCu192DzgeKfTE+bzMW8++eDh2ox2eKX7C5NscD9z/A9fXvDM1mi9zZrx2sHx7rV9r5wqliL13p77P30UFYppT8WFZfa4rx0jxZAVVRpx9X2lq19fmIZOdoWV23dqDuKhe5VDx5iu6tWD9LXfFiN7raX9J5gZbnurBd5966HVum9+rNP2lfmSottDuOYg7TwsKNH80j5NpvDaN2su8/dePODZnzg5FpZ81KgCO3lFRvN+KApgV0C+8G/5rfNeVeQ3zX1r3N6lT3+ylIzPnym7po3YxfdNc9/pEAT3OiR627/b3/mb+VT/XdiR7c+l/VNuhvbTy+3Oc9LTj9R1vx47n3RPxN/KQAAHIICAMAhKAAAHIICAGDHLV777mX/YsbvvLlQ1lQMskmpMbXjZM3ydZrA3Hu6TXAteOsdWVOW0gT1U48/ZcbtnbodZ1uzTVCXV2kn1Y7ANp6RV/BVO04Tg0OHacHVmwsW9FnY418ZpaW65eG4yZNlblC1TSKnvAT9NoHLqbTEJl7bOzRRN3iQTdI3NevWkIMCSeStjTaJvctoLYxbs6FBD7PdzrXXb5Y1U2ttErskrm+poRWB7p+SENefq2vTBGaR1/+zKFBg5neq7QhsDVleqt8S8K+DbDbbry60C9+rM+O9J+rWsRnv6XV16/VcXaGvXbdX9FYS+FJEU4sWoB481X7BIhc4v2+sson1JWv19e2PXOB/0bZu/ZJA1isqDL0RVmx8f8fQHxSvAQAGhNtHAACHoAAAcAgKAIAdN9H8y2uuNONcj24hGSVtJ8Rsrya8MoFib3/mjcXaBbEo0AE1nbfJ55Ym7Vqa9rYYzIeqKAMvVXHSJn/b2zU5W16hVbgd7R19Vvi2tbX9t0negq2B51KUs8+lOLAdaGkgyZn3qmDT3VrhW1lpE/DBqzJw7mJZm5xdv/AlWdMSSMbGcjYxOHmUVs4mvATmlnZ9nFSgXW9J0l4XKe+1DCWMC5LeY8Vjel0kvITxE4vekzVHzNQvWCzZ0GzGu9fqdaGp5yhatdkm/Nc36hcAagbZ127aWFudXtARqH5f+J7dLjcd6CQQC5yDuNeVYOre2r222OsAEJMV4e04c16yPxH4fO1vZ1tw+9y7o38mEs0AgAHh9hEAwCEoAAB23JzCj358hRmXJjTuJRL23nXG63JZkExqTiHuFQm1tWsuYlNDQ587vS1+7VVZU1Ft792mAzdu69etlblJFfb51W1tlzXVlbqjWEeHvV/fGLgP3pOxB1Ga0nvePb1+MU7h3rg9d4PG7iprxk2eInPNTfbcNTVoEc+k6TPMuK1Ji5aWL3hN5pLePeDQ/fuYt6ag2HsuLR36mlekEn3mFBJFoRyRnev/W6zvne30/RpYFHzn28l4Qs/TtH326rObbKhTbcwr6gu87aJ4YOe13m6bJ7vnPrvzHPqPnAIAYEC4fQQAcAgKAACHoAAA2HETzT+78kdmnAlkbJcsfcuM99prf1mzdOUKmWvxEp+tgURzyyq7zWVBZbGNvc2dWqCT9pJpzV3aYTGQq4wm1Ay1j+MlhwsygRaOOa9bY3WVFrjVb7GFTJ1ZPYBs4LH94qrOQEFSaaDTZXuXTX4PrdBOsY1eQV15IPmdDiQwK0rs7+v1itkKqgMFdf62qI2tWgwZywd+ob8mULw2xSumKikOdFINfGzz37G5QOFWlIv1+Thrl6+UuZcWvqkLscMg0QwAGBBuHwEAHIICAGDHzSncdft1ZryhfousGeQ1VdvabO+dF4wcoU3c3l623ozXLVsqaxJbtOCqLGXPXSZwyl9dvsmMP7Rbrax58q01Mje8yh5nfVOLrAlWN3l2G6M7kTV7zfU2NmmzvZJivafvZzXiMS0EzPZqgVde7s0HGtt5BYST9rTFbAWVVZV9noNcP/IA237MnwjkUO7+0339eizgn42cAgBgQLh9BABwCAoAAIegAADYMRLNP/v8STJXNcQmTNu9HcYKUl4jxkV12ll0r9FaODVvuU1aV/bY5HDBqg4tQNq3xiZaX1ilie2utC1WK8ppwVcsEMP9ly/0Mm1t7+5zV6pJe+4payoqvF3k+n0N+JeUdr7MejvNFdzz5wfso/Tv0gTQTySaAQADwu0jAIBDUAAAOAQFAMCOkWj+lzOPl7niTKsZV1cNljVNbbYy95m33pM1nT2aCPWKaYOGj58sc2XV1WYcC3W19IReliIvOVyQy9jK3HS3dm594ulnZK7d244TwI6PRDMAYEC4fQQAcAgKAABH21duR9bkvOKqQgdS7ynlWwOdNiO7y9iIPbTTZtTUKFN3Pzav74NavrbvNQDwAcVfCgAAh6AAAHAICgAAh6AAANgxitcAAP1H8RoAYEC4fQQAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAACHoAAAcAgKAAAnEfVTPp/v71IAwHaKvxQAAA5BAQDgEBQAAA5BAQDgEBQAAA5BAQDgEBQAAA5BAQDgEBQAANF/+b/pLC7gY/kwuwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import packages\n",
    "import json\n",
    "\n",
    "import PIL as pil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# load images and other informations\n",
    "DATA_ROOT = \"./data\"\n",
    "\n",
    "def load_split(root: str, subsample: int = 10, split: str =\"train\"):\n",
    "    with open(f\"{root}/transforms_{split}.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        imgs, poses = [], []\n",
    "        for frame in data[\"frames\"]:\n",
    "            image_path = f\"{root}/{frame['file_path'][2:]}.png\"\n",
    "\n",
    "            # subsample and append image\n",
    "            img = np.array(pil.Image.open(image_path).convert(\"RGB\"))\n",
    "            if subsample > 1:\n",
    "                img = img[::subsample, ::subsample]\n",
    "            imgs.append(img)\n",
    "\n",
    "            # append pose\n",
    "            poses.append(np.array(frame[\"transform_matrix\"], dtype=np.float32))\n",
    "\n",
    "    # normalize images and cast poses\n",
    "    imgs = np.array(imgs).astype(np.float32) / 255.0\n",
    "    poses = np.array(poses).astype(np.float32)\n",
    "    H, W = imgs[0].shape[:2]\n",
    "\n",
    "    # get focal from camera_angle_x\n",
    "    focal = 0.5 * W / np.tan(0.5 * data[\"camera_angle_x\"])\n",
    "    return torch.from_numpy(imgs), torch.from_numpy(poses), H, W, focal\n",
    "\n",
    "imgs_train, poses_train, H, W, focal = load_split(DATA_ROOT)\n",
    "print(\"Shape of train images: \", imgs_train.shape)\n",
    "print(\"Shape of poses: \", poses_train.shape)\n",
    "print(\"Focal: \", focal)\n",
    "\n",
    "plt.imshow(imgs_train[5].cpu().detach().numpy())\n",
    "plt.axis(\"off\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780c00a",
   "metadata": {},
   "source": [
    "Now we need to prepare two functions responsible for the rendering of the scene. `get_rays` will generate a grid of direction vectors for given camera-to-world transformation matrix. Basically we can prepare direction vectors in the normal coordinate system (origins in $\\mathbf{0}$) and then apply $\\mathbf{T}_i$ matrix to transform them to the camera world. It is performed using:\n",
    "\n",
    "$$\n",
    "    \\mathbf{d}_{\\text{world}} = \\mathbf{d}_{\\text{camera}} \\mathbf{R}_i,\n",
    "$$\n",
    "where $\\mathbf{R}$ is the top $3 \\times 3$ part of $\\mathbf{T}_i$ representing the rotation part. The origins are all the same for every vector and are represented by the last column of $\\mathbf{T}_i$.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"figures/camtransform.png\" />\n",
    "</p>\n",
    "\n",
    "Second function, `render_rays`, will perform volume rendering. First we draw linear samples from the interval $[t_n, t_f]$, but to futher increase the versitality of the underlying MLP approximation authors suggest using a stratified sampling approach where we partition [tn, tf ] into N evenly-spaced bins and then draw one sample uniformly at random from within each bin:\n",
    "\n",
    "$$\n",
    "    t_i  \\sim \\mathcal{U} \\Big[t_n + \\frac{i+1}{N}(t_f - t_n), t_n + \\frac{i}{N}(t_f - t_n) \\Big].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c658078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "\n",
    "class ModelBase(nn.Module, ABC):    \n",
    "    pass\n",
    "\n",
    "def _prepare_direction_mesh(focal: float, H: int, W: int) -> torch.Tensor:\n",
    "    # create a grid of values scaled by H and W\n",
    "    i, j = torch.meshgrid(torch.arange(W, device=DEVICE), torch.arange(H, device=DEVICE), indexing='xy')\n",
    "    cx, cy = W * 0.5, H * 0.5\n",
    "    # pinhole camera\n",
    "    return torch.stack([(i - cx)/focal, -(j - cy)/focal, -torch.ones_like(i)], -1)\n",
    "\n",
    "def get_rays(dir_mesh: torch.Tensor, camera_to_world: torch.Tensor):\n",
    "    # get the camera direction in world coordinate system\n",
    "    rays_dir = dir_mesh @ camera_to_world[:3, :3].T\n",
    "    # origins are the same for each vector\n",
    "    rays_origin = camera_to_world[:3, 3].expand(rays_dir.shape)\n",
    "    # normalize ray_direcrions\n",
    "    return rays_origin, F.normalize(rays_dir, dim=-1) \n",
    "\n",
    "def render_rays(\n",
    "    model: ModelBase, \n",
    "    rays_o: torch.Tensor,\n",
    "    rays_d: torch.Tensor,\n",
    "    near_plane=1.0,\n",
    "    far_plane=6.0,\n",
    "    n_samples=32,\n",
    "    perturb=True\n",
    "):\n",
    "    # sample depths\n",
    "    t_vals = torch.linspace(0.0, 1.0, n_samples, device=DEVICE)\n",
    "    # linear interploate between near and fat planes\n",
    "    z_vals = near_plane * (1.0 - t_vals) + far_plane * t_vals\n",
    "    # cast to the size of ray object\n",
    "    z_vals = z_vals.expand(rays_o.shape[:-1] + (n_samples,))\n",
    "\n",
    "    # perturn values - draw from uniform bins\n",
    "    if perturb:\n",
    "        mids = 0.5 * (z_vals[..., 1:] + z_vals[..., :-1])\n",
    "        upper = torch.cat([mids, z_vals[..., -1:]], -1)\n",
    "        lower = torch.cat([z_vals[..., :1], mids], -1)\n",
    "        t_rand = torch.rand(z_vals.shape, device=DEVICE)\n",
    "        z_vals = lower + (upper - lower) * t_rand\n",
    "\n",
    "    # points along rays r_ij(t) = o_ij + d_ij * t\n",
    "    # rays are of size (H, W, 3) and z_vals is (H, W, n)\n",
    "    # we can make it into (H, W, 1, 3) and (H, W, n, 1) and perform elementwise multiplication\n",
    "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., None]\n",
    "    dirs = rays_d[..., None, :].expand_as(pts)\n",
    "\n",
    "    # query network with aggregated points and direcrions\n",
    "    B = pts.shape[:-1]\n",
    "    rgb, sigma = model(pts.reshape(-1,3), dirs.reshape(-1,3))\n",
    "    # reshape rbg and sigma back to initial shape\n",
    "    rgb = rgb.reshape(B + (3,))\n",
    "    sigma = sigma.reshape(B)\n",
    "\n",
    "    # volumetric compositing\n",
    "    deltas = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "    delta_last = 1e10 * torch.ones_like(deltas[..., :1])\n",
    "    deltas = torch.cat([deltas, delta_last], -1)\n",
    "\n",
    "    # alpha_i: per-sample opacity in [0,1]\n",
    "    # (sigma_i is predicted density, deltas_i is the distance to the next sample)\n",
    "    alpha = 1.0 - torch.exp(-sigma * deltas)\n",
    "    survival = 1.0 - alpha + 1e-10 \n",
    "\n",
    "    survival_with_one = torch.cat(\n",
    "        [torch.ones_like(survival[..., :1]), survival],\n",
    "        dim=-1\n",
    "    )\n",
    "\n",
    "    cumprod_inclusive = torch.cumprod(survival_with_one, dim=-1)\n",
    "    T = cumprod_inclusive[..., :-1]\n",
    "    weights = T * alpha\n",
    "\n",
    "    rgb_map = torch.sum(weights[..., None] * rgb, -2)\n",
    "    depth_map = torch.sum(weights * z_vals, -1)\n",
    "    return rgb_map, depth_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d8980",
   "metadata": {},
   "source": [
    "With helper functions written, we can finally define the model. Authors found that MLP which directly operate on $xyz\\theta\\phi$ input coordinates results in renderings that perform poorly at representing high-frequency variation in color and geometry. They leverage positional embedding to mitigate those effect. They define an embedding function $\\gamma: \\mathbb{R} \\rightarrow \\mathbb{R}^{2L}$ as:\n",
    "\n",
    "$$\n",
    " \\gamma(p) = \\Big(\\sin(2^0 \\pi p), \\cos(2^0 \\pi p),\\cdots, \\sin(2^{L - 1} \\pi p), \\cos(2^{L - 1}\\pi p) \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c851c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosEnc(nn.Module):\n",
    "    def __init__(self, in_dims, num_freqs=10):\n",
    "        super().__init__()\n",
    "        self.in_dims = in_dims\n",
    "        self.num_freqs = num_freqs\n",
    "        self.freqs = 2.0 ** torch.arange(num_freqs)\n",
    "\n",
    "    @property\n",
    "    def out_dims(self):\n",
    "        return self.in_dims * (self.num_freqs * 2  + 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc = [x]\n",
    "        for f in self.freqs:\n",
    "            enc += [torch.sin(f * x), torch.cos(f * x)]\n",
    "        return torch.cat(enc, dim=-1)\n",
    "    \n",
    "\n",
    "class TinyNeRF(nn.Module):\n",
    "    def __init__(self, Lx=10, Ld=4, dim=128):\n",
    "        super().__init__()\n",
    "        # encoding layers\n",
    "        self.pe_x = PosEnc(3, Lx)\n",
    "        self.pe_d = PosEnc(3, Ld)\n",
    "        in_x = self.pe_x.out_dims\n",
    "        in_d = self.pe_d.out_dims\n",
    "\n",
    "        # MLP\n",
    "        self.fc1 = nn.Linear(in_x, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.fc3 = nn.Linear(dim, dim)\n",
    "        self.fc4 = nn.Linear(dim + in_x, dim) # residual connection\n",
    "        self.fc_sigma = nn.Linear(dim, 1)\n",
    "\n",
    "        self.fc_feat = nn.Linear(dim, dim)\n",
    "        self.fc_dir  = nn.Linear(dim + in_d, dim//2)\n",
    "        self.fc_rgb  = nn.Linear(dim//2, 3)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); \n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, d):\n",
    "        # x: (...,3) points \n",
    "        # d: (...,3) ray dirs\n",
    "\n",
    "        # encoding and infering coordinates\n",
    "        x_enc = self.pe_x(x)\n",
    "        y = F.relu(self.fc1(x_enc))\n",
    "        y = F.relu(self.fc2(y))\n",
    "        y = F.relu(self.fc3(y))\n",
    "\n",
    "        # residual \n",
    "        y = torch.cat([x_enc, y], dim=-1)\n",
    "        y = F.relu(self.fc4(y))\n",
    "\n",
    "        # output\n",
    "        sigma = F.relu(self.fc_sigma(y))\n",
    "\n",
    "        # use coodinates as additional features for estimating rgb\n",
    "        # and concat them with embedded angle\n",
    "        d_enc = self.pe_d(d)\n",
    "        feat = F.relu(self.fc_feat(y))\n",
    "\n",
    "        y_dir = torch.cat([feat, d_enc], dim=-1)\n",
    "        y_dir = F.relu(self.fc_dir(y_dir))\n",
    "\n",
    "        # output\n",
    "        rgb = torch.sigmoid(self.fc_rgb(y_dir))\n",
    "        return rgb, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881aae3",
   "metadata": {},
   "source": [
    "With the model and all helped functions defines we can finally begin training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ff3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MESH = _prepare_direction_mesh(focal, H, W)\n",
    "\n",
    "model = TinyNeRF(Lx=10, Ld=4, dim=32).to(DEVICE)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "near, far = 1.0, 6.0    # blender synthetic scenes\n",
    "n_samples = 32          # samples per ray\n",
    "batch_rays = 1024       # rays per step\n",
    "steps = 15_000          # training steps\n",
    "show_every = 1_000\n",
    "\n",
    "imgs = imgs_train.to(DEVICE)\n",
    "poses = poses_train.to(DEVICE)\n",
    "\n",
    "# precompute rays for all train images\n",
    "all_rays_o, all_rays_d, all_rgbs = [], [], []\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    ro, rd = get_rays(DIR_MESH, poses[i])\n",
    "    all_rays_o.append(ro.reshape(-1, 3))\n",
    "    all_rays_d.append(rd.reshape(-1, 3))\n",
    "    all_rgbs.append(imgs[i].reshape(-1, 3))\n",
    "\n",
    "all_rays_o = torch.cat(all_rays_o, 0)\n",
    "all_rays_d = torch.cat(all_rays_d, 0)\n",
    "all_rgbs   = torch.cat(all_rgbs, 0)\n",
    "N_total_rays = all_rays_o.shape[0]\n",
    "print(\"Total train rays:\", N_total_rays)\n",
    "\n",
    "bar = tqdm(range(1, steps + 1),\n",
    "    desc=\"Training\",\n",
    "    unit=\"step\",\n",
    "    dynamic_ncols=True,\n",
    "    smoothing=0.1,\n",
    "    leave=True\n",
    ")\n",
    "\n",
    "# traning loop\n",
    "model.train()\n",
    "for step in bar:\n",
    "    # pick random batch of rays (not from one image, but from all of the rays)\n",
    "    idx = torch.randint(0, N_total_rays, (batch_rays,), device=DEVICE)\n",
    "    rays_o = all_rays_o[idx]\n",
    "    rays_d = all_rays_d[idx]\n",
    "    target = all_rgbs[idx]\n",
    "\n",
    "    # infer model and backpropagate\n",
    "    rgb_pred, _ = render_rays(model, rays_o, rays_d, near, far, n_samples=n_samples)\n",
    "    loss = F.mse_loss(rgb_pred, target)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        psnr = -10.0 * torch.log10(loss.detach())\n",
    "        bar.set_postfix(loss=f\"{loss.item():.5f}\", psnr=f\"{psnr:.2f}\")\n",
    "\n",
    "    if step % show_every == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # render fifth train view (low-res)\n",
    "            ro, rd = get_rays(DIR_MESH, poses[5])\n",
    "            ro, rd = ro.reshape(-1,3), rd.reshape(-1,3)\n",
    "            rgb, _ = render_rays(model, ro, rd, near, far, n_samples=n_samples, perturb=False)\n",
    "            img_pred = rgb.reshape(H, W, 3).clamp(0,1).cpu().numpy()\n",
    "            img_gt   = imgs[5].cpu().numpy()\n",
    "\n",
    "            # preview\n",
    "            side_by_side = (np.hstack([img_gt, img_pred]) * 255).astype(np.uint8)\n",
    "            plt.imshow(side_by_side)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef1846",
   "metadata": {},
   "source": [
    "Given the trained model, we can generate a gif of rotating around our modeled scene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc6299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [00:07<00:00, 16.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def pose_spherical(theta_deg, radius, z=2.8):\n",
    "    theta = np.deg2rad(theta_deg)\n",
    "\n",
    "    # camera position on a circle at height z\n",
    "    cam_pos = np.array([\n",
    "        radius * np.cos(theta),\n",
    "        radius * np.sin(theta),\n",
    "        z\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    target   = np.array([0, 0, 0], dtype=np.float32)\n",
    "    world_up = np.array([0, 0, 1], dtype=np.float32)\n",
    "\n",
    "    # view direction from camera to target\n",
    "    forward = target - cam_pos\n",
    "    forward /= np.linalg.norm(forward)\n",
    "\n",
    "    # duild a right-handed camera frame where z_cam = -forward\n",
    "    z_cam = -forward\n",
    "    # right\n",
    "    x_cam = np.cross(world_up, z_cam); x_cam /= np.linalg.norm(x_cam)  \n",
    "    # up (orthonormal)\n",
    "    y_cam = np.cross(z_cam, x_cam)\n",
    "\n",
    "    # camera-to-world: columns are the camera axes expressed in world coords\n",
    "    c2w = np.eye(4, dtype=np.float32)\n",
    "    c2w[:3, :3] = np.stack([x_cam, y_cam, z_cam], axis=1)\n",
    "    # translation\n",
    "    c2w[:3, 3]  = cam_pos \n",
    "    return torch.from_numpy(c2w).to(DEVICE)\n",
    "\n",
    "n_frames  = 120\n",
    "radius    = 4\n",
    "\n",
    "model.eval()\n",
    "imgs = []\n",
    "for i in trange(n_frames):\n",
    "    theta = i * 360.0 / n_frames\n",
    "    c2w = pose_spherical(theta, radius)\n",
    "    ro, rd = get_rays(DIR_MESH, c2w)\n",
    "    ro, rd = ro.reshape(-1,3), rd.reshape(-1,3)\n",
    "    rgb, _ = render_rays(model, ro, rd, near, far, n_samples=n_samples, perturb=False)\n",
    "    img_pred = (rgb.reshape(H, W, 3).clamp(0,1).detach().cpu().numpy()*255).astype(np.uint8)\n",
    "    imgs.append(img_pred)\n",
    "\n",
    "imageio.mimsave(\"orbit.gif\", imgs, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad69c0",
   "metadata": {},
   "source": [
    "If you run this code with lower subsampling, bigger hidden size and more iterations, you should end up with animation similar to this one.\n",
    "\n",
    "![](figures/render.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeRF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
